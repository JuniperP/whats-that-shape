{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What's That Shape?\n",
    "We will be using a neural network to identify the shape in a picture (square, circle, or triange).\n",
    "## PyTorch\n",
    "PyTorch is a package that lets you make neural networks while taking advantage of the GPU if CUDA (for NVIDIA cards) is installed.\n",
    "\n",
    "TorchVision is related to PyTorch, but is mostly used for the image aspect of training nn's.\n",
    "## Tensors?\n",
    "A PyTorch Tensor is basically the same as a numpy array: it does not know anything about deep learning or computational graphs or gradients, and is just a generic n-dimensional array to be used for arbitrary numeric computation.\n",
    "## Train? Val (Test)?\n",
    "The training set is used to train the neural network, while the val/valid (validation) set is used to test how correct it is on a data set it has never encountered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# variables\n",
    "batch_size=16\n",
    "learning_rate=3e-5\n",
    "epochs=200\n",
    "\n",
    "# setting to use gpu if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the transformations\n",
    "transformations = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3), # turns image into grayscale with 3 color channels\n",
    "    transforms.CenterCrop(224), # crops it into a 224, 224\n",
    "    transforms.ToTensor(), # converts image into a tensor\n",
    "    transforms.Normalize(mean=[0.4], std=[0.23]) # normalizes tensor\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading each shape's train and validation into a dataset\n",
    "\n",
    "train_set = datasets.ImageFolder(\"shapes/train/\", transform = transformations)\n",
    "val_set = datasets.ImageFolder(\"shapes/valid/\", transform = transformations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading datasets into dataloader\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained Models\n",
    "Since it would take many magnitudes more of data to train with and it would take extreme amounts of time, we use a pretrained data model (as a base network) that companies process with amounts of data and processing power unavailable to the general public.\n",
    "\n",
    "![Pretrained Model Comparison](https://www.mathworks.com/help/deeplearning/ug/pretrained20a.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get pretrained model using torchvision.models as models library\n",
    "\n",
    "model = models.densenet161(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseNet(\n",
       "  (features): Sequential(\n",
       "    (conv0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (norm0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu0): ReLU(inplace=True)\n",
       "    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (denseblock1): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(144, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(240, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(288, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(336, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition1): _Transition(\n",
       "      (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock2): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(240, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(288, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(336, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(432, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(528, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(624, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(624, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(720, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition2): _Transition(\n",
       "      (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock3): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(432, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(528, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(624, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(624, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(720, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(816, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(864, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(912, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(912, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer13): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(960, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer14): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1008, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1008, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer15): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1056, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer16): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1104, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer17): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer18): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1200, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer19): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1248, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer20): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1296, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1296, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer21): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1344, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer22): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1392, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer23): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1440, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer24): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1488, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer25): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1536, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer26): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1584, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1584, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer27): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1632, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer28): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1680, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1680, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer29): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1728, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer30): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1776, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1776, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer31): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1824, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer32): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1872, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1872, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer33): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1920, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer34): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1968, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1968, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer35): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(2016, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(2016, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer36): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(2064, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(2064, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition3): _Transition(\n",
       "      (norm): BatchNorm2d(2112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv): Conv2d(2112, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock4): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1056, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1104, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1200, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1248, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1296, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1296, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1344, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1392, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1440, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1488, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1536, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1584, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1584, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer13): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1632, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer14): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1680, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1680, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer15): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1728, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer16): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1776, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1776, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer17): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1824, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer18): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1872, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1872, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer19): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1920, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer20): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1968, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1968, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer21): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(2016, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(2016, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer22): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(2064, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(2064, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer23): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(2112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(2112, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer24): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(2160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(2160, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (norm5): BatchNorm2d(2208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=2208, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the image classifier\n",
    "classifier_input = model.classifier.in_features\n",
    "num_labels = 3\n",
    "\n",
    "classifier = nn.Sequential(nn.Linear(classifier_input, 1024),\n",
    "                           nn.ReLU(),\n",
    "                           nn.Linear(1024, 512),\n",
    "                           nn.ReLU(),\n",
    "                           nn.Linear(512, num_labels),\n",
    "                           nn.LogSoftmax(dim=1))\n",
    "\n",
    "# moving to cpu/gpu\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the loss\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# optimizing\n",
    "optimizer = optim.Adam(model.classifier.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy Dropping\n",
    "TBA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Accuracy: 0.000%\t Learning Rate: 3e-05\n",
      "Training Loss: -0.103084 \tValidation Loss: 1.522795\n",
      "Epoch: 2\n",
      "Accuracy: 0.000%\t Learning Rate: 3e-05\n",
      "Training Loss: -0.377644 \tValidation Loss: -0.881178\n",
      "Epoch: 3\n",
      "Accuracy: 1.667%\t Learning Rate: 3e-05\n",
      "Training Loss: -0.616542 \tValidation Loss: -1.201097\n",
      "Epoch: 4\n",
      "Accuracy: 0.625%\t Learning Rate: 3e-05\n",
      "Training Loss: -0.889957 \tValidation Loss: -1.488723\n",
      "Epoch: 5\n",
      "Accuracy: 1.667%\t Learning Rate: 3e-05\n",
      "Training Loss: -1.195929 \tValidation Loss: -1.690717\n",
      "Epoch: 6\n",
      "Accuracy: 0.625%\t Learning Rate: 3e-05\n",
      "Training Loss: -1.449956 \tValidation Loss: -2.022733\n",
      "Epoch: 7\n",
      "Accuracy: 1.250%\t Learning Rate: 3e-05\n",
      "Training Loss: -1.781617 \tValidation Loss: -2.278127\n",
      "Epoch: 8\n",
      "Accuracy: 1.875%\t Learning Rate: 3e-05\n",
      "Training Loss: -2.019700 \tValidation Loss: -2.481838\n",
      "Epoch: 9\n",
      "Accuracy: 4.375%\t Learning Rate: 3e-05\n",
      "Training Loss: -2.302036 \tValidation Loss: -2.782879\n",
      "Epoch: 10\n",
      "Accuracy: 8.542%\t Learning Rate: 3e-05\n",
      "Training Loss: -2.533564 \tValidation Loss: -3.094653\n",
      "Epoch: 11\n",
      "Accuracy: 9.167%\t Learning Rate: 3e-05\n",
      "Training Loss: -2.883770 \tValidation Loss: -3.310740\n",
      "Epoch: 12\n",
      "Accuracy: 11.667%\t Learning Rate: 3e-05\n",
      "Training Loss: -3.118807 \tValidation Loss: -3.584495\n",
      "Epoch: 13\n",
      "Accuracy: 12.917%\t Learning Rate: 3e-05\n",
      "Training Loss: -3.392064 \tValidation Loss: -3.853139\n",
      "Epoch: 14\n",
      "Accuracy: 20.000%\t Learning Rate: 3e-05\n",
      "Training Loss: -3.670823 \tValidation Loss: -4.212677\n",
      "Epoch: 15\n",
      "Accuracy: 20.208%\t Learning Rate: 3e-05\n",
      "Training Loss: -3.926623 \tValidation Loss: -4.449562\n",
      "Epoch: 16\n",
      "Accuracy: 26.458%\t Learning Rate: 3e-05\n",
      "Training Loss: -4.191809 \tValidation Loss: -4.748064\n",
      "Epoch: 17\n",
      "Accuracy: 35.417%\t Learning Rate: 3e-05\n",
      "Training Loss: -4.527346 \tValidation Loss: -5.083683\n",
      "Epoch: 18\n",
      "Accuracy: 34.583%\t Learning Rate: 3e-05\n",
      "Training Loss: -4.795781 \tValidation Loss: -5.292820\n",
      "Epoch: 19\n",
      "Accuracy: 37.708%\t Learning Rate: 3e-05\n",
      "Training Loss: -5.047511 \tValidation Loss: -5.563709\n",
      "Epoch: 20\n",
      "Accuracy: 43.333%\t Learning Rate: 3e-05\n",
      "Training Loss: -5.336987 \tValidation Loss: -5.836289\n",
      "Epoch: 21\n",
      "Accuracy: 48.125%\t Learning Rate: 3e-05\n",
      "Training Loss: -5.614908 \tValidation Loss: -6.153380\n",
      "Epoch: 22\n",
      "Accuracy: 53.333%\t Learning Rate: 3e-05\n",
      "Training Loss: -5.892777 \tValidation Loss: -6.464659\n",
      "Epoch: 23\n",
      "Accuracy: 51.250%\t Learning Rate: 3e-05\n",
      "Training Loss: -6.165403 \tValidation Loss: -6.696053\n",
      "Epoch: 24\n",
      "Accuracy: 55.000%\t Learning Rate: 3e-05\n",
      "Training Loss: -6.441197 \tValidation Loss: -7.011525\n",
      "Epoch: 25\n",
      "Accuracy: 55.417%\t Learning Rate: 3e-05\n",
      "Training Loss: -6.737354 \tValidation Loss: -7.250285\n",
      "Epoch: 26\n",
      "Accuracy: 55.417%\t Learning Rate: 3e-05\n",
      "Training Loss: -7.027722 \tValidation Loss: -7.586570\n",
      "Epoch: 27\n",
      "Accuracy: 56.250%\t Learning Rate: 3e-05\n",
      "Training Loss: -7.273691 \tValidation Loss: -7.853802\n",
      "Epoch: 28\n",
      "Accuracy: 58.750%\t Learning Rate: 3e-05\n",
      "Training Loss: -7.544287 \tValidation Loss: -8.133538\n",
      "Epoch: 29\n",
      "Accuracy: 59.792%\t Learning Rate: 3e-05\n",
      "Training Loss: -7.800697 \tValidation Loss: -8.401932\n",
      "Epoch: 30\n",
      "Accuracy: 58.750%\t Learning Rate: 3e-05\n",
      "Training Loss: -8.086663 \tValidation Loss: -8.751559\n",
      "Epoch: 31\n",
      "Accuracy: 60.417%\t Learning Rate: 3e-05\n",
      "Training Loss: -8.386396 \tValidation Loss: -8.966626\n",
      "Epoch: 32\n",
      "Accuracy: 57.708%\t Learning Rate: 3e-05\n",
      "Training Loss: -8.654012 \tValidation Loss: -9.177715\n",
      "Epoch: 33\n",
      "Accuracy: 61.042%\t Learning Rate: 3e-05\n",
      "Training Loss: -8.956375 \tValidation Loss: -9.568745\n",
      "Epoch: 34\n",
      "Accuracy: 59.792%\t Learning Rate: 3e-05\n",
      "Training Loss: -9.227742 \tValidation Loss: -9.773895\n",
      "Epoch: 35\n",
      "Accuracy: 62.083%\t Learning Rate: 3e-05\n",
      "Training Loss: -9.480703 \tValidation Loss: -10.078024\n",
      "Epoch: 36\n",
      "Accuracy: 59.583%\t Learning Rate: 3e-05\n",
      "Training Loss: -9.767041 \tValidation Loss: -10.354569\n",
      "Epoch: 37\n",
      "Accuracy: 61.667%\t Learning Rate: 3e-05\n",
      "Training Loss: -10.041130 \tValidation Loss: -10.680149\n",
      "Epoch: 38\n",
      "Accuracy: 59.375%\t Learning Rate: 3e-05\n",
      "Training Loss: -10.305396 \tValidation Loss: -10.839475\n",
      "Epoch: 39\n",
      "Accuracy: 60.417%\t Learning Rate: 3e-05\n",
      "Training Loss: -10.591823 \tValidation Loss: -11.170321\n",
      "Epoch: 40\n",
      "Accuracy: 58.333%\t Learning Rate: 3e-05\n",
      "Training Loss: -10.878032 \tValidation Loss: -11.419856\n",
      "Epoch: 41\n",
      "Accuracy: 60.000%\t Learning Rate: 3e-05\n",
      "Training Loss: -11.139237 \tValidation Loss: -11.729779\n",
      "Epoch: 42\n",
      "Accuracy: 63.125%\t Learning Rate: 3e-05\n",
      "Training Loss: -11.388560 \tValidation Loss: -12.000651\n",
      "Epoch: 43\n",
      "Accuracy: 61.667%\t Learning Rate: 3e-05\n",
      "Training Loss: -11.684479 \tValidation Loss: -12.318065\n",
      "Epoch: 44\n",
      "Accuracy: 61.458%\t Learning Rate: 3e-05\n",
      "Training Loss: -11.958623 \tValidation Loss: -12.503003\n",
      "Epoch: 45\n",
      "Accuracy: 61.042%\t Learning Rate: 3e-05\n",
      "Training Loss: -12.229181 \tValidation Loss: -12.887439\n",
      "Epoch: 46\n",
      "Accuracy: 60.625%\t Learning Rate: 3e-05\n",
      "Training Loss: -12.500817 \tValidation Loss: -13.152099\n",
      "Epoch: 47\n",
      "Accuracy: 59.792%\t Learning Rate: 3e-05\n",
      "Training Loss: -12.823529 \tValidation Loss: -13.302262\n",
      "Epoch: 48\n",
      "Accuracy: 61.667%\t Learning Rate: 3e-05\n",
      "Training Loss: -13.041689 \tValidation Loss: -13.700067\n",
      "Epoch: 49\n",
      "Accuracy: 61.667%\t Learning Rate: 3e-05\n",
      "Training Loss: -13.304598 \tValidation Loss: -13.960535\n",
      "Epoch: 50\n",
      "Accuracy: 58.958%\t Learning Rate: 3e-05\n",
      "Training Loss: -13.628875 \tValidation Loss: -14.287195\n",
      "Epoch: 51\n",
      "Accuracy: 61.250%\t Learning Rate: 3e-05\n",
      "Training Loss: -13.903434 \tValidation Loss: -14.654018\n",
      "Epoch: 52\n",
      "Accuracy: 61.042%\t Learning Rate: 3e-05\n",
      "Training Loss: -14.161802 \tValidation Loss: -14.826538\n",
      "Epoch: 53\n",
      "Accuracy: 58.958%\t Learning Rate: 3e-05\n",
      "Training Loss: -14.428076 \tValidation Loss: -15.198369\n",
      "Epoch: 54\n",
      "Accuracy: 60.625%\t Learning Rate: 3e-05\n",
      "Training Loss: -14.713168 \tValidation Loss: -15.330740\n",
      "Epoch: 55\n",
      "Accuracy: 62.292%\t Learning Rate: 3e-05\n",
      "Training Loss: -15.021681 \tValidation Loss: -15.669511\n",
      "Epoch: 56\n",
      "Accuracy: 63.125%\t Learning Rate: 3e-05\n",
      "Training Loss: -15.245127 \tValidation Loss: -15.875367\n",
      "Epoch: 57\n",
      "Accuracy: 61.042%\t Learning Rate: 3e-05\n",
      "Training Loss: -15.541095 \tValidation Loss: -16.296060\n",
      "Epoch: 58\n",
      "Accuracy: 62.083%\t Learning Rate: 3e-05\n",
      "Training Loss: -15.828844 \tValidation Loss: -16.418550\n",
      "Epoch: 59\n",
      "Accuracy: 57.917%\t Learning Rate: 3e-05\n",
      "Training Loss: -16.106667 \tValidation Loss: -16.676136\n",
      "Epoch: 60\n",
      "Accuracy: 63.750%\t Learning Rate: 3e-05\n",
      "Training Loss: -16.405124 \tValidation Loss: -17.053784\n",
      "Epoch: 61\n",
      "Accuracy: 63.333%\t Learning Rate: 3e-05\n",
      "Training Loss: -16.696893 \tValidation Loss: -17.273325\n",
      "Epoch: 62\n",
      "Accuracy: 61.250%\t Learning Rate: 3e-05\n",
      "Training Loss: -16.897343 \tValidation Loss: -17.558280\n",
      "Epoch: 63\n",
      "Accuracy: 61.667%\t Learning Rate: 3e-05\n",
      "Training Loss: -17.204920 \tValidation Loss: -17.866457\n",
      "Epoch: 64\n",
      "Accuracy: 58.958%\t Learning Rate: 3e-05\n",
      "Training Loss: -17.460744 \tValidation Loss: -18.096883\n",
      "Epoch: 65\n",
      "Accuracy: 61.250%\t Learning Rate: 3e-05\n",
      "Training Loss: -17.772448 \tValidation Loss: -18.374691\n",
      "Epoch: 66\n",
      "Accuracy: 61.875%\t Learning Rate: 3e-05\n",
      "Training Loss: -18.005414 \tValidation Loss: -18.630947\n",
      "Epoch: 67\n",
      "Accuracy: 61.250%\t Learning Rate: 3e-05\n",
      "Training Loss: -18.277315 \tValidation Loss: -18.973859\n",
      "Epoch: 68\n",
      "Accuracy: 60.833%\t Learning Rate: 3e-05\n",
      "Training Loss: -18.607957 \tValidation Loss: -19.313954\n",
      "Epoch: 69\n",
      "Accuracy: 59.583%\t Learning Rate: 3e-05\n",
      "Training Loss: -18.901329 \tValidation Loss: -19.632961\n",
      "Epoch: 70\n",
      "Accuracy: 61.458%\t Learning Rate: 3e-05\n",
      "Training Loss: -19.147865 \tValidation Loss: -19.864312\n",
      "Epoch: 71\n",
      "Accuracy: 63.958%\t Learning Rate: 3e-05\n",
      "Training Loss: -19.381180 \tValidation Loss: -20.093176\n",
      "Epoch: 72\n",
      "Accuracy: 61.667%\t Learning Rate: 3e-05\n",
      "Training Loss: -19.698664 \tValidation Loss: -20.468930\n",
      "Epoch: 73\n",
      "Accuracy: 62.708%\t Learning Rate: 3e-05\n",
      "Training Loss: -19.956599 \tValidation Loss: -20.619662\n",
      "Epoch: 74\n",
      "Accuracy: 62.292%\t Learning Rate: 3e-05\n",
      "Training Loss: -20.208782 \tValidation Loss: -20.728440\n",
      "Epoch: 75\n",
      "Accuracy: 62.708%\t Learning Rate: 3e-05\n",
      "Training Loss: -20.525342 \tValidation Loss: -21.191036\n",
      "Epoch: 76\n",
      "Accuracy: 61.667%\t Learning Rate: 3e-05\n",
      "Training Loss: -20.796808 \tValidation Loss: -21.206935\n",
      "Epoch: 77\n",
      "Accuracy: 61.667%\t Learning Rate: 3e-05\n",
      "Training Loss: -21.093898 \tValidation Loss: -21.642781\n",
      "Epoch: 78\n",
      "Accuracy: 64.583%\t Learning Rate: 3e-05\n",
      "Training Loss: -21.325234 \tValidation Loss: -22.140727\n",
      "Epoch: 79\n",
      "Accuracy: 62.292%\t Learning Rate: 3e-05\n",
      "Training Loss: -21.612625 \tValidation Loss: -22.337934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 80\n",
      "Accuracy: 64.167%\t Learning Rate: 3e-05\n",
      "Training Loss: -21.908240 \tValidation Loss: -22.785803\n",
      "Epoch: 81\n",
      "Accuracy: 65.208%\t Learning Rate: 3e-05\n",
      "Training Loss: -22.176081 \tValidation Loss: -22.846296\n",
      "Epoch: 82\n",
      "Accuracy: 62.708%\t Learning Rate: 3e-05\n",
      "Training Loss: -22.450271 \tValidation Loss: -23.120429\n",
      "Epoch: 83\n",
      "Accuracy: 62.917%\t Learning Rate: 3e-05\n",
      "Training Loss: -22.711926 \tValidation Loss: -23.639084\n",
      "Epoch: 84\n",
      "Accuracy: 63.542%\t Learning Rate: 3e-05\n",
      "Training Loss: -23.027908 \tValidation Loss: -23.744009\n",
      "Epoch: 85\n",
      "Accuracy: 62.917%\t Learning Rate: 3e-05\n",
      "Training Loss: -23.311824 \tValidation Loss: -23.967613\n",
      "Epoch: 86\n",
      "Accuracy: 65.208%\t Learning Rate: 3e-05\n",
      "Training Loss: -23.558080 \tValidation Loss: -24.337151\n",
      "Epoch: 87\n",
      "Accuracy: 64.792%\t Learning Rate: 3e-05\n",
      "Training Loss: -23.819815 \tValidation Loss: -24.632671\n",
      "Epoch: 88\n",
      "Accuracy: 61.875%\t Learning Rate: 3e-05\n",
      "Training Loss: -24.094675 \tValidation Loss: -24.995563\n",
      "Epoch: 89\n",
      "Accuracy: 64.792%\t Learning Rate: 3e-05\n",
      "Training Loss: -24.371903 \tValidation Loss: -25.109478\n",
      "Epoch: 90\n",
      "Accuracy: 62.083%\t Learning Rate: 3e-05\n",
      "Training Loss: -24.655170 \tValidation Loss: -25.465965\n",
      "Epoch: 91\n",
      "Accuracy: 64.583%\t Learning Rate: 3e-05\n",
      "Training Loss: -24.930454 \tValidation Loss: -25.588462\n",
      "Epoch: 92\n",
      "Accuracy: 64.583%\t Learning Rate: 3e-05\n",
      "Training Loss: -25.240081 \tValidation Loss: -25.874614\n",
      "Epoch: 93\n",
      "Accuracy: 65.208%\t Learning Rate: 3e-05\n",
      "Training Loss: -25.495193 \tValidation Loss: -26.376709\n",
      "Epoch: 94\n",
      "Accuracy: 62.083%\t Learning Rate: 3e-05\n",
      "Training Loss: -25.783848 \tValidation Loss: -26.553385\n",
      "Epoch: 95\n",
      "Accuracy: 63.750%\t Learning Rate: 3e-05\n",
      "Training Loss: -26.038782 \tValidation Loss: -26.973714\n",
      "Epoch: 96\n",
      "Accuracy: 63.542%\t Learning Rate: 3e-05\n",
      "Training Loss: -26.306158 \tValidation Loss: -27.155254\n",
      "Epoch: 97\n",
      "Accuracy: 68.125%\t Learning Rate: 3e-05\n",
      "Training Loss: -26.598155 \tValidation Loss: -27.511700\n",
      "Epoch: 98\n",
      "Accuracy: 63.542%\t Learning Rate: 3e-05\n",
      "Training Loss: -26.849305 \tValidation Loss: -27.665265\n",
      "Epoch: 99\n",
      "Accuracy: 64.792%\t Learning Rate: 3e-05\n",
      "Training Loss: -27.101849 \tValidation Loss: -27.921417\n",
      "Epoch: 100\n",
      "Accuracy: 66.458%\t Learning Rate: 3e-05\n",
      "Training Loss: -27.420462 \tValidation Loss: -28.256784\n",
      "Epoch: 101\n",
      "Accuracy: 63.333%\t Learning Rate: 3e-05\n",
      "Training Loss: -27.693613 \tValidation Loss: -28.387410\n",
      "Epoch: 102\n",
      "Accuracy: 63.750%\t Learning Rate: 3e-05\n",
      "Training Loss: -27.947136 \tValidation Loss: -28.755519\n",
      "Epoch: 103\n",
      "Accuracy: 66.667%\t Learning Rate: 3e-05\n",
      "Training Loss: -28.273583 \tValidation Loss: -29.070569\n",
      "Epoch: 104\n",
      "Accuracy: 63.542%\t Learning Rate: 3e-05\n",
      "Training Loss: -28.533440 \tValidation Loss: -29.229711\n",
      "Epoch: 105\n",
      "Accuracy: 66.042%\t Learning Rate: 3e-05\n",
      "Training Loss: -28.776954 \tValidation Loss: -29.367779\n",
      "Epoch: 106\n",
      "Accuracy: 66.042%\t Learning Rate: 3e-05\n",
      "Training Loss: -29.051897 \tValidation Loss: -29.876127\n",
      "Epoch: 107\n",
      "Accuracy: 65.417%\t Learning Rate: 3e-05\n",
      "Training Loss: -29.292640 \tValidation Loss: -30.175007\n",
      "Epoch: 108\n",
      "Accuracy: 67.083%\t Learning Rate: 3e-05\n",
      "Training Loss: -29.628176 \tValidation Loss: -30.408230\n",
      "Epoch: 109\n",
      "Accuracy: 69.375%\t Learning Rate: 3e-05\n",
      "Training Loss: -29.893554 \tValidation Loss: -30.745843\n",
      "Epoch: 110\n",
      "Accuracy: 68.750%\t Learning Rate: 3e-05\n",
      "Training Loss: -30.136793 \tValidation Loss: -30.964025\n",
      "Epoch: 111\n",
      "Accuracy: 66.667%\t Learning Rate: 3e-05\n",
      "Training Loss: -30.469196 \tValidation Loss: -31.252424\n",
      "Epoch: 112\n",
      "Accuracy: 65.000%\t Learning Rate: 3e-05\n",
      "Training Loss: -30.727267 \tValidation Loss: -31.361355\n",
      "Epoch: 113\n",
      "Accuracy: 65.625%\t Learning Rate: 3e-05\n",
      "Training Loss: -30.987643 \tValidation Loss: -31.935549\n",
      "Epoch: 114\n",
      "Accuracy: 65.208%\t Learning Rate: 3e-05\n",
      "Training Loss: -31.219402 \tValidation Loss: -32.109862\n",
      "Epoch: 115\n",
      "Accuracy: 64.167%\t Learning Rate: 3e-05\n",
      "Training Loss: -31.538312 \tValidation Loss: -32.326429\n",
      "Epoch: 116\n",
      "Accuracy: 67.708%\t Learning Rate: 3e-05\n",
      "Training Loss: -31.856769 \tValidation Loss: -32.755684\n",
      "Epoch: 117\n",
      "Accuracy: 67.292%\t Learning Rate: 3e-05\n",
      "Training Loss: -32.095362 \tValidation Loss: -33.117325\n",
      "Epoch: 118\n",
      "Accuracy: 64.583%\t Learning Rate: 3e-05\n",
      "Training Loss: -32.366058 \tValidation Loss: -33.113265\n",
      "Epoch: 119\n",
      "Accuracy: 68.750%\t Learning Rate: 3e-05\n",
      "Training Loss: -32.646162 \tValidation Loss: -33.607912\n",
      "Epoch: 120\n",
      "Accuracy: 65.417%\t Learning Rate: 3e-05\n",
      "Training Loss: -32.962305 \tValidation Loss: -33.659907\n",
      "Epoch: 121\n",
      "Accuracy: 63.333%\t Learning Rate: 3e-05\n",
      "Training Loss: -33.201139 \tValidation Loss: -34.130898\n",
      "Epoch: 122\n",
      "Accuracy: 65.000%\t Learning Rate: 3e-05\n",
      "Training Loss: -33.451345 \tValidation Loss: -34.377573\n",
      "Epoch: 123\n",
      "Accuracy: 66.667%\t Learning Rate: 3e-05\n",
      "Training Loss: -33.717836 \tValidation Loss: -34.755158\n",
      "Epoch: 124\n",
      "Accuracy: 66.667%\t Learning Rate: 3e-05\n",
      "Training Loss: -34.036774 \tValidation Loss: -35.071451\n",
      "Epoch: 125\n",
      "Accuracy: 64.375%\t Learning Rate: 3e-05\n",
      "Training Loss: -34.302743 \tValidation Loss: -35.274971\n",
      "Epoch: 126\n",
      "Accuracy: 67.708%\t Learning Rate: 3e-05\n",
      "Training Loss: -34.610829 \tValidation Loss: -35.632476\n",
      "Epoch: 127\n",
      "Accuracy: 69.375%\t Learning Rate: 3e-05\n",
      "Training Loss: -34.845413 \tValidation Loss: -36.019732\n",
      "Epoch: 128\n",
      "Accuracy: 62.292%\t Learning Rate: 3e-05\n",
      "Training Loss: -35.158458 \tValidation Loss: -36.035356\n",
      "Epoch: 129\n",
      "Accuracy: 68.333%\t Learning Rate: 3e-05\n",
      "Training Loss: -35.414848 \tValidation Loss: -36.303346\n",
      "Epoch: 130\n",
      "Accuracy: 68.958%\t Learning Rate: 3e-05\n",
      "Training Loss: -35.670484 \tValidation Loss: -36.592748\n",
      "Epoch: 131\n",
      "Accuracy: 66.875%\t Learning Rate: 3e-05\n",
      "Training Loss: -35.975933 \tValidation Loss: -37.045374\n",
      "Epoch: 132\n",
      "Accuracy: 66.250%\t Learning Rate: 3e-05\n",
      "Training Loss: -36.291958 \tValidation Loss: -37.140479\n",
      "Epoch: 133\n",
      "Accuracy: 66.250%\t Learning Rate: 3e-05\n",
      "Training Loss: -36.483949 \tValidation Loss: -37.453459\n",
      "Epoch: 134\n",
      "Accuracy: 65.625%\t Learning Rate: 3e-05\n",
      "Training Loss: -36.810770 \tValidation Loss: -37.475185\n",
      "Epoch: 135\n",
      "Accuracy: 68.958%\t Learning Rate: 3e-05\n",
      "Training Loss: -37.045808 \tValidation Loss: -37.991102\n",
      "Epoch: 136\n",
      "Accuracy: 65.625%\t Learning Rate: 3e-05\n",
      "Training Loss: -37.339610 \tValidation Loss: -37.982333\n",
      "Epoch: 137\n",
      "Accuracy: 68.333%\t Learning Rate: 3e-05\n",
      "Training Loss: -37.651612 \tValidation Loss: -38.482488\n",
      "Epoch: 138\n",
      "Accuracy: 66.250%\t Learning Rate: 3e-05\n",
      "Training Loss: -37.861200 \tValidation Loss: -38.532993\n",
      "Epoch: 139\n",
      "Accuracy: 67.708%\t Learning Rate: 3e-05\n",
      "Training Loss: -38.173066 \tValidation Loss: -38.842960\n",
      "Epoch: 140\n",
      "Accuracy: 66.875%\t Learning Rate: 3e-05\n",
      "Training Loss: -38.424208 \tValidation Loss: -39.562778\n",
      "Epoch: 141\n",
      "Accuracy: 67.708%\t Learning Rate: 3e-05\n",
      "Training Loss: -38.732918 \tValidation Loss: -39.708517\n",
      "Epoch: 142\n",
      "Accuracy: 68.958%\t Learning Rate: 3e-05\n",
      "Training Loss: -39.011754 \tValidation Loss: -39.946268\n",
      "Epoch: 143\n",
      "Accuracy: 69.583%\t Learning Rate: 3e-05\n",
      "Training Loss: -39.317856 \tValidation Loss: -40.327993\n",
      "Epoch: 144\n",
      "Accuracy: 68.958%\t Learning Rate: 3e-05\n",
      "Training Loss: -39.533795 \tValidation Loss: -40.530932\n",
      "Epoch: 145\n",
      "Accuracy: 66.250%\t Learning Rate: 3e-05\n",
      "Training Loss: -39.880251 \tValidation Loss: -40.766099\n",
      "Epoch: 146\n",
      "Accuracy: 66.667%\t Learning Rate: 3e-05\n",
      "Training Loss: -40.048611 \tValidation Loss: -40.831335\n",
      "Epoch: 147\n",
      "Accuracy: 68.958%\t Learning Rate: 3e-05\n",
      "Training Loss: -40.328598 \tValidation Loss: -41.252580\n",
      "Epoch: 148\n",
      "Accuracy: 69.583%\t Learning Rate: 3e-05\n",
      "Training Loss: -40.667402 \tValidation Loss: -41.425960\n",
      "Epoch: 149\n",
      "Accuracy: 67.917%\t Learning Rate: 3e-05\n",
      "Training Loss: -40.923430 \tValidation Loss: -41.806418\n",
      "Epoch: 150\n",
      "Accuracy: 66.875%\t Learning Rate: 3e-05\n",
      "Training Loss: -41.178949 \tValidation Loss: -41.930362\n",
      "Epoch: 151\n",
      "Accuracy: 68.958%\t Learning Rate: 3e-05\n",
      "Training Loss: -41.433010 \tValidation Loss: -42.458506\n",
      "Epoch: 152\n",
      "Accuracy: 67.917%\t Learning Rate: 3e-05\n",
      "Training Loss: -41.754288 \tValidation Loss: -42.649167\n",
      "Epoch: 153\n",
      "Accuracy: 66.875%\t Learning Rate: 3e-05\n",
      "Training Loss: -42.021866 \tValidation Loss: -42.833626\n",
      "Epoch: 154\n",
      "Accuracy: 68.958%\t Learning Rate: 3e-05\n",
      "Training Loss: -42.276788 \tValidation Loss: -43.269131\n",
      "Epoch: 155\n",
      "Accuracy: 68.958%\t Learning Rate: 3e-05\n",
      "Training Loss: -42.593699 \tValidation Loss: -43.403453\n",
      "Epoch: 156\n",
      "Accuracy: 65.833%\t Learning Rate: 3e-05\n",
      "Training Loss: -42.842853 \tValidation Loss: -43.623964\n",
      "Epoch: 157\n",
      "Accuracy: 67.500%\t Learning Rate: 3e-05\n",
      "Training Loss: -43.121715 \tValidation Loss: -44.346274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 158\n",
      "Accuracy: 67.917%\t Learning Rate: 3e-05\n",
      "Training Loss: -43.366817 \tValidation Loss: -44.310558\n",
      "Epoch: 159\n",
      "Accuracy: 67.917%\t Learning Rate: 3e-05\n",
      "Training Loss: -43.677884 \tValidation Loss: -44.720363\n",
      "Epoch: 160\n",
      "Accuracy: 66.875%\t Learning Rate: 3e-05\n",
      "Training Loss: -43.930577 \tValidation Loss: -44.648048\n",
      "Epoch: 161\n",
      "Accuracy: 70.625%\t Learning Rate: 3e-05\n",
      "Training Loss: -44.227303 \tValidation Loss: -45.601615\n",
      "Epoch: 162\n",
      "Accuracy: 69.583%\t Learning Rate: 3e-05\n",
      "Training Loss: -44.523565 \tValidation Loss: -45.344204\n",
      "Epoch: 163\n",
      "Accuracy: 70.625%\t Learning Rate: 3e-05\n",
      "Training Loss: -44.736508 \tValidation Loss: -45.481369\n",
      "Epoch: 164\n",
      "Accuracy: 68.958%\t Learning Rate: 3e-05\n",
      "Training Loss: -44.992571 \tValidation Loss: -45.862477\n",
      "Epoch: 165\n",
      "Accuracy: 67.917%\t Learning Rate: 3e-05\n",
      "Training Loss: -45.244393 \tValidation Loss: -46.239271\n",
      "Epoch: 166\n",
      "Accuracy: 67.917%\t Learning Rate: 3e-05\n",
      "Training Loss: -45.557693 \tValidation Loss: -46.558350\n",
      "Epoch: 167\n",
      "Accuracy: 67.917%\t Learning Rate: 3e-05\n",
      "Training Loss: -45.847143 \tValidation Loss: -47.088174\n",
      "Epoch: 168\n",
      "Accuracy: 66.875%\t Learning Rate: 3e-05\n",
      "Training Loss: -46.131522 \tValidation Loss: -46.851565\n",
      "Epoch: 169\n",
      "Accuracy: 68.542%\t Learning Rate: 3e-05\n",
      "Training Loss: -46.380797 \tValidation Loss: -47.097401\n",
      "Epoch: 170\n",
      "Accuracy: 70.208%\t Learning Rate: 3e-05\n",
      "Training Loss: -46.678977 \tValidation Loss: -47.131578\n",
      "Epoch: 171\n",
      "Accuracy: 67.917%\t Learning Rate: 3e-05\n",
      "Training Loss: -46.969230 \tValidation Loss: -47.390706\n",
      "Epoch: 172\n",
      "Accuracy: 68.958%\t Learning Rate: 3e-05\n",
      "Training Loss: -47.216435 \tValidation Loss: -47.905672\n",
      "Epoch: 173\n",
      "Accuracy: 70.000%\t Learning Rate: 3e-05\n",
      "Training Loss: -47.573434 \tValidation Loss: -48.171269\n",
      "Epoch: 174\n",
      "Accuracy: 66.875%\t Learning Rate: 3e-05\n",
      "Training Loss: -47.745243 \tValidation Loss: -48.733401\n",
      "Epoch: 175\n",
      "Accuracy: 69.583%\t Learning Rate: 3e-05\n",
      "Training Loss: -48.064389 \tValidation Loss: -48.891897\n",
      "Epoch: 176\n",
      "Accuracy: 67.500%\t Learning Rate: 3e-05\n",
      "Training Loss: -48.358785 \tValidation Loss: -49.252319\n",
      "Epoch: 177\n",
      "Accuracy: 65.833%\t Learning Rate: 3e-05\n",
      "Training Loss: -48.574830 \tValidation Loss: -49.878318\n",
      "Epoch: 178\n",
      "Accuracy: 69.583%\t Learning Rate: 3e-05\n",
      "Training Loss: -48.929973 \tValidation Loss: -50.200971\n",
      "Epoch: 179\n",
      "Accuracy: 68.958%\t Learning Rate: 3e-05\n",
      "Training Loss: -49.200792 \tValidation Loss: -50.287863\n",
      "Epoch: 180\n",
      "Accuracy: 68.958%\t Learning Rate: 3e-05\n",
      "Training Loss: -49.445005 \tValidation Loss: -50.260410\n",
      "Epoch: 181\n",
      "Accuracy: 65.417%\t Learning Rate: 3e-05\n",
      "Training Loss: -49.669335 \tValidation Loss: -50.802647\n",
      "Epoch: 182\n",
      "Accuracy: 68.958%\t Learning Rate: 3e-05\n",
      "Training Loss: -50.006974 \tValidation Loss: -50.920132\n",
      "Epoch: 183\n",
      "Accuracy: 66.875%\t Learning Rate: 3e-05\n",
      "Training Loss: -50.267216 \tValidation Loss: -51.404407\n",
      "Epoch: 184\n",
      "Accuracy: 69.167%\t Learning Rate: 3e-05\n",
      "Training Loss: -50.554085 \tValidation Loss: -51.411755\n",
      "Epoch: 185\n",
      "Accuracy: 68.125%\t Learning Rate: 3e-05\n",
      "Training Loss: -50.840052 \tValidation Loss: -51.720823\n",
      "Epoch: 186\n",
      "Accuracy: 66.250%\t Learning Rate: 3e-05\n",
      "Training Loss: -51.112417 \tValidation Loss: -52.327729\n",
      "Epoch: 187\n",
      "Accuracy: 66.875%\t Learning Rate: 3e-05\n",
      "Training Loss: -51.400734 \tValidation Loss: -52.449206\n",
      "Epoch: 188\n",
      "Accuracy: 66.875%\t Learning Rate: 3e-05\n",
      "Training Loss: -51.623419 \tValidation Loss: -52.687374\n",
      "Epoch: 189\n",
      "Accuracy: 67.292%\t Learning Rate: 3e-05\n",
      "Training Loss: -51.871067 \tValidation Loss: -53.263264\n",
      "Epoch: 190\n",
      "Accuracy: 66.875%\t Learning Rate: 3e-05\n",
      "Training Loss: -52.148481 \tValidation Loss: -53.198718\n",
      "Epoch: 191\n",
      "Accuracy: 68.958%\t Learning Rate: 3e-05\n",
      "Training Loss: -52.458080 \tValidation Loss: -53.137650\n",
      "Epoch: 192\n",
      "Accuracy: 67.500%\t Learning Rate: 3e-05\n",
      "Training Loss: -52.720550 \tValidation Loss: -53.874139\n",
      "Epoch: 193\n",
      "Accuracy: 69.792%\t Learning Rate: 3e-05\n",
      "Training Loss: -53.007691 \tValidation Loss: -53.672825\n",
      "Epoch: 194\n",
      "Accuracy: 66.875%\t Learning Rate: 3e-05\n",
      "Training Loss: -53.264139 \tValidation Loss: -53.945846\n",
      "Epoch: 195\n",
      "Accuracy: 66.875%\t Learning Rate: 3e-05\n",
      "Training Loss: -53.606048 \tValidation Loss: -54.623270\n",
      "Epoch: 196\n",
      "Accuracy: 70.208%\t Learning Rate: 3e-05\n",
      "Training Loss: -53.867765 \tValidation Loss: -54.446233\n",
      "Epoch: 197\n",
      "Accuracy: 67.500%\t Learning Rate: 3e-05\n",
      "Training Loss: -54.031078 \tValidation Loss: -55.055662\n",
      "Epoch: 198\n",
      "Accuracy: 69.167%\t Learning Rate: 3e-05\n",
      "Training Loss: -54.361599 \tValidation Loss: -55.419171\n",
      "Epoch: 199\n",
      "Accuracy: 69.167%\t Learning Rate: 3e-05\n",
      "Training Loss: -54.717083 \tValidation Loss: -55.534428\n",
      "Epoch: 200\n",
      "Accuracy: 66.875%\t Learning Rate: 3e-05\n",
      "Training Loss: -54.871742 \tValidation Loss: -55.908513\n"
     ]
    }
   ],
   "source": [
    "acc_x = []\n",
    "acc_y = []\n",
    "moving_lr = learning_rate\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "    accuracy = 0\n",
    "    \n",
    "    # train the model\n",
    "    model.train()\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        # move to device\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # clear optimizers\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward\n",
    "        output = model.forward(inputs)\n",
    "        \n",
    "        # calculate loss\n",
    "        loss = criterion(output, labels)\n",
    "        \n",
    "        # backpropogate\n",
    "        loss.backward()\n",
    "        \n",
    "        # adjust params\n",
    "        optimizer.step()\n",
    "        \n",
    "        # add the loss to the iteration's total\n",
    "        train_loss += loss.item()*inputs.size(0)\n",
    "    \n",
    "    # evaluate model\n",
    "    model.eval()\n",
    "    \n",
    "    # perform test on validation set (no training)\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            \n",
    "            # move to device\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "        \n",
    "            # clear optimizers\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "            # forward\n",
    "            output = model.forward(inputs)\n",
    "        \n",
    "            # calculate loss\n",
    "            loss = criterion(output, labels)\n",
    "            \n",
    "            # add loss to iteration's total\n",
    "            val_loss += loss.item()*inputs.size(0)\n",
    "            \n",
    "            # getting percentage loss\n",
    "            output = torch.exp(output)\n",
    "            \n",
    "            # obtaining top_class\n",
    "            top_p, top_class = output.topk(1, dim=1)\n",
    "            \n",
    "            # test the correctness of the top class\n",
    "            equals = top_class == labels.view(*top_class.shape)\n",
    "            \n",
    "            # mean accuracy and add to total accuracy\n",
    "            accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "            \n",
    "    # get the averages for the entire epoch\n",
    "    train_loss = train_loss/len(train_loader.dataset)\n",
    "    valid_loss = val_loss/len(val_loader.dataset)\n",
    "    avg_acc = accuracy/len(val_loader)*100\n",
    "    \n",
    "    # print out the information\n",
    "    print('Epoch: {}'.format(epoch+1))\n",
    "    print('Accuracy: {:.3f}% \\tLearning Rate: {}'.format(avg_acc, moving_lr))\n",
    "    print('Training Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(train_loss, valid_loss))\n",
    "    \n",
    "    # store data in list\n",
    "    acc_x.append(epoch+1)\n",
    "    acc_y.append(avg_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create plot\n",
    "plt.plot(acc_x, acc_y, color='navy', linewidth=2 if epoch<=100 else 1, label='Test')\n",
    "\n",
    "# setting labels and title\n",
    "plt.title(f'Shapes Training Results | 1st Learning Rate: {learning_rate}')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy in %')\n",
    "\n",
    "# visuals\n",
    "plt.xlim([0, round(epoch+0.07*epoch)])\n",
    "plt.ylim([0, 100])\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
